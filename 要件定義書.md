# 要件定義書

## プロジェクト名
WhisperWebAppProject

## 概要
このプロジェクトは、OpenAIの音声認識APIを使用して音声をテキストに変換するWebアプリケーションです。Next.jsとReactを使用して構築されています。

## 機能要件

### 1. 音声録音
- ユーザーが「スタート」ボタンをクリックすると、音声の録音が開始される。
- 録音は、音声が検出された場合のみ開始される。
- 録音中に音声が3秒間検出されない場合、録音が停止し、音声データがバックエンドに送信される。

### 2. 音声データの処理
- 録音された音声データは、テキストに変換され、ローカルストレージに保存される。
- ユーザーは、変換されたテキストの正確性を確認するために、保存された音声データを再生できる。

### 3. 設定オプション
- ユーザーは、音声検出の感度を調整するために`minDecibels`と`maxDecibels`の値を設定できる。
- 録音の最大待機時間を設定するための`maxPause`オプションがある。

### 4. エラーハンドリング
- 録音中にエラーが発生した場合、適切なエラーメッセージを表示する。

### 5. 音声データの削除
- ユーザーは、変換されたテキストを削除することができる。

## 非機能要件
- アプリケーションは、デスクトップおよびモバイルのSafari、Chromeで動作すること。
- 音声データの処理は、ffmpegを使用して行う。
- OpenAI APIを使用する場合、APIキーが必要。

## 環境要件
- Node.jsとnpmがインストールされていること。
- ffmpegがシステムにインストールされていること。

## インストール手順
1. リポジトリをクローンする。
2. 依存関係をインストールする。
3. `.env`ファイルを作成し、APIキーを設定する。
4. アプリケーションを起動する。

## 使用方法
- アプリケーションを起動後、ブラウザで`http://localhost:3005/`にアクセスする。

この要件定義書は、プロジェクトの開発に必要な基本的な情報を提供します。必要に応じて、詳細を追加してください。